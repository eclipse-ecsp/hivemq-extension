#Device authorization keys
whitelisted.users=haa_api,haa_notification
device.mqtt.publish.topics=events,alerts
device.mqtt.subscribe.topics=config
mqtt.topic.infix.2d=2d/
mqtt.topic.infix.2c=2c/
user.mqtt.subscribe.topics=notification
internal.user.mqtt.subscribe.topics=config,notification
mqtt.user.prefix=harman/dev/

#Kafka details
kafka.broker.url=10.0.0.40:9092,10.0.0.218:9092,10.0.0.23:9092
kafka.acks=1
kafka.linger.ms=250
kafka.num.put.retries=4
kafka.key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
kafka.value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
kafka.partitioner=org.apache.kafka.clients.producer.internals.DefaultPartitioner
kafka.replace.classloader=true
#set this to true if you don't want any writes to kafka. purpose is to determine time taken without kafka in the processing thread 
kafka.no.puts=false
#set this to true if you want async puts. but this means no ordering guarantees
kafka.register.sync.puts=false
kafka.device.events.sync.puts=false
#use -1 to disable logging. logging can tell you how much time it takes to process x number of messages if x is given as the frequency
kafka.log.frequency=10000
#determine the key to use for kafka puts from the topic name in MQTT
kafka.record.key.start.pos=0
kafka.record.key.end.pos=6

kafka.request.timeout.ms=600000
kafka.compression.type=lz4
kafka.batch.size=0
kafka.max.block.ms=30000
kafka.max.in.flight.requests.per.connection=1

kafka.metadata.max.age.ms:60000
kafka.request.timeout.ms:600000
kafka.reconnect.backoff.max.ms:100000
kafka.reconnect.backoff.ms:30000

#kafka Topics
kafka.sink.topic.events=haa-harman-dev-events
kafka.sink.topic.alerts=haa-harman-dev-alerts

#SSL Configuration
kafka.ssl.enable=true
kafka.ssl.client.auth=required
kafka.client.keystore=/kafka/ssl/kafka.client.keystore.jks
kafka.client.keystore.password=test
kafka.client.key.password=test
kafka.client.truststore=/kafka/ssl/kafka.client.truststore.jks
kafka.client.truststore.password=test

#Kinesis Topics
kinesis.sink.topic.events=san-harman-dev-events
kinesis.sink.topic.alerts=san-harman-dev-alerts
kinesis.sink.topic.connect=connect
kinesis.sink.topic.disconnect=disconnect

#mqtt topics
mqtt.topicFormatter=org.eclipse.ecsp.hivemq.utils.IgniteTopicFormatter
mqtt.topic.prefix=haa/harman/dev/
mqtt.topic.generalevents.suffix=/events
mqtt.topic.alerts.suffix=/alerts
mqtt.decompress.enabled=true

#Streaming properties
bootstrap.servers=localhost:9092
zookeeper.connect=localhost:2181

##Redis properties
redis.host.name=localhost
redis.port=6379
redis.database=-1
redis.sentinel.master.name=redis-sentinel
redis.sentinel.hostAndPort=127.0.0.1:26379,127.0.0.1:26380,127.0.0.1:26381
redis.ttl.in.seconds=660

#The modes are SINGLE,REPLICA,CLUSTER,SENTINEL
redis.mode=SENTINEL
redis.single.endpoint=127.0.0.1:6379
redis.replica.endpoints=127.0.0.1:6379,127.0.0.1:6380
redis.cluster.endpoints=127.0.0.1:6379,127.0.0.1:6380
redis.sentinel.endpoints=127.0.0.1:26379,127.0.0.1:26380,127.0.0.1:26381
redis.master.name=redis-sentinel
redis.master.pool.max.size=5
redis.master.idle.min=1
redis.slave.pool.max.size=5
redis.slave.idle.min=1
redis.scan.interval=2000
redis.database=0
redis.max.pool.size=5
redis.min.idle=1
redis.pipeline.batch.size=500
redis.read.timeout=10000
redis.retry.interval=10000
redis.retry.attempts=5


#HiveMq cluster discovery via Redis, node detial update interval in Redis
update.interval.in.minutes=10

#oAuth properties
oauth.introspect.url=https://ignite-is.ahanet.net/oauth2/introspect

#Cumulative logging configuration
log.counts=true
log.counts.minutes=1
log.per.pdid=false

#JWT 
#this public key is without any prefix and suffix and is extracted from provided wso.pem file using command $ openssl x509 -in wso2carbon_token_signer.pem -pubkey  -out test_wso_publickey.txt
jwt.publickey.path=/opt/hivemq/conf/wso_harman_dev_publickey.txt

#Plugin configuration
authentication.impl.class=org.eclipse.ecsp.hivemq.auth.authentication.JWTAuthentication
authorization.impl.class=org.eclipse.ecsp.hivemq.auth.authorization.Authorizer
topic.mapper.impl.class=org.eclipse.ecsp.hivemq.routing.TopicMapperCloudMobile
client.lifecycle.impl.class=org.eclipse.ecsp.hivemq.callbacks.ClientLifeCycleEvents
hivemq.sink.impl.class=org.eclipse.ecsp.analytics.stream.base.dao.impl.KafkaSinkNode
device.to.vehicle.mapper.impl=org.eclipse.ecsp.hivemq.mapper.DefaultDeviceToVehicleMapper
swap.response.topic.name=disconnect

#Ignite internal topics 
kafka.sink.topic.connect=connect
kafka.sink.topic.disconnect=disconnect

wrap.with.ignite.event.enabled=true
ingestion.serializer.impl=org.eclipse.ecsp.serializer.IngestionSerializerFSTImpl
allowed.blob.sources=ignite,telematics
allowed.blob.encodings=gpb,json
#transform.<blob source>.<blob type>. Mapping of source and type to kafka topic
transform.ignite.json=events,alerts
transform.telematics.gpb=ecall,bcall
environment=test

#Mqtt topic to kafka topic routing
#<serviceid (mqtt topic)>,<service name (sp)>,<kafka topic>,<device status required>;...
mqtt.topic.service.mapping=tcushieldevents,,haa-harman-dev-events,false:events,,haa-harman-dev-events,false:alerts,,haa-harman-dev-alerts,false:ecall,ecall,haa-harman-dev-ecall,true:bcall,bcall,haa-harman-dev-bcall,true:ro,ro,haa-harman-dev-ro,true